{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas_datareader.data as pdr\n",
    "import yfinance as yf\n",
    "from blog3.models import ModelTrunk\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def lr_lambda(epoch, warmup_epochs=15, decay_epochs=100, initial_lr=1e-6, base_lr=1e-3, min_lr=5e-5):\n",
    "    if epoch <= warmup_epochs:\n",
    "        pct = epoch / warmup_epochs\n",
    "        return ((base_lr - initial_lr) * pct) + initial_lr\n",
    "\n",
    "    if epoch > warmup_epochs and epoch < warmup_epochs+decay_epochs:\n",
    "        pct = 1 - ((epoch - warmup_epochs) / decay_epochs)\n",
    "        return ((base_lr - min_lr) * pct) + min_lr\n",
    "\n",
    "    return min_lr / base_lr\n",
    "\n",
    "\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 100\n",
    "SEQ_LEN = 60  # The number of past days to consider\n",
    "MODEL_DIM = 128  # Dimensionality of the model\n",
    "NUM_HEADS = 2  # Number of attention heads\n",
    "NUM_LAYERS = 1  # Number of attention layers\n",
    "DROPOUT = 0.1  # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "data = pdr.get_data_yahoo(\"AAPL\", start=\"2015-01-01\", end=\"2021-09-01\")\n",
    "prices = data[\"Close\"].values.reshape(-1, 1)\n",
    "\n",
    "# # Scale the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "prices = scaler.fit_transform(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(SEQ_LEN, len(prices) - 1):\n",
    "    inputs.append(prices[i - SEQ_LEN:i])\n",
    "    targets.append(prices[i - SEQ_LEN + 1:i + 1])\n",
    "\n",
    "inputs = torch.tensor(np.array(inputs)).float()\n",
    "targets = torch.tensor(np.array(targets)).float()\n",
    "# inputs\n",
    "# 1618 sentences\n",
    "# 60 words\n",
    "\n",
    "# targets\n",
    "# 1618 words\n",
    "# 60 words\n",
    "\n",
    "# (torch.Size([1617, 60, 1]), torch.Size([1617, 60, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_inputs, test_inputs, train_targets, test_targets = train_test_split(\n",
    "    inputs, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_inputs, test_targets)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = ModelTrunk(time2vec_dim=MODEL_DIM, num_heads=NUM_HEADS, head_size=MODEL_DIM,\n",
    "                   ff_dim=MODEL_DIM, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "\n",
    "\n",
    "# Initialize the optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [3840, 1] but got: [3840, 128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m outputs \u001b[39m=\u001b[39m model(batch_inputs)\n\u001b[1;32m      8\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(outputs, batch_targets)\n\u001b[1;32m     10\u001b[0m \u001b[39m# Backward pass and optimize\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/work/bio/embeddings/stock2vec/transformers/models.py:147\u001b[0m, in \u001b[0;36mModelTrunk.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs):\n\u001b[1;32m    144\u001b[0m     \u001b[39m# inputs is expected to be [batch_size, sequence_length, feature_dim]\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m     \u001b[39m# Get time embeddings\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     time_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtime2vec(inputs)\n\u001b[1;32m    149\u001b[0m     \u001b[39m# Concatenate the inputs and time embeddings\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[39m# [batch_size, sequence_length, feature_dim + time2vec_dim]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([inputs, time_embedding], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/work/bio/embeddings/stock2vec/transformers/models.py:56\u001b[0m, in \u001b[0;36mTime2Vec.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m# expand weight_angle shape to [batch_size, sequence_length, kernel_size]\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m# expand weight_angle shape to [batch_size, sequence_length, kernel_size, 1]\u001b[39;00m\n\u001b[1;32m     54\u001b[0m weight_angle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_angle\u001b[39m.\u001b[39munsqueeze(\n\u001b[1;32m     55\u001b[0m     \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> 56\u001b[0m angular_transformation \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(\n\u001b[1;32m     57\u001b[0m     inputs, weight_angle) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_angle\n\u001b[1;32m     58\u001b[0m angular_transformation \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msin(angular_transformation)\n\u001b[1;32m     60\u001b[0m \u001b[39m# Combine linear and angular transformations\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m# Then reshape it to a 2D tensor\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [3840, 1] but got: [3840, 128]."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(N_EPOCHS):\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = F.mse_loss(outputs, batch_targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{N_EPOCHS}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
